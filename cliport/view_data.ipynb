{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cliport_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Sep 22 2020 00:56:01\n"
     ]
    }
   ],
   "source": [
    "from cliport.dataset import RavensDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/home/ubuntu/cliport/data/stack-block-pyramid-seq-seen-colors-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"dataset\":{\"type\": \"single\",\n",
    "                  \"images\": True,\n",
    "                  \"cache\": True,\n",
    "                  \"augment\":{\"theta_sigma\":60},\n",
    "                  \"cache_size\": 400},\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RavensDataset(train_data_dir, cfg, n_demos=1000, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.sample_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHE HAS BEEN FILLED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     batch_data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_ds))\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:264\u001b[0m, in \u001b[0;36mRavensDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     episode_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_episodes))\n\u001b[0;32m--> 264\u001b[0m episode, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(episode_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimages, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache)\n\u001b[1;32m    266\u001b[0m \u001b[39m# Is the task sequential like stack-block-pyramid-seq?\u001b[39;00m\n\u001b[1;32m    267\u001b[0m is_sequential_task \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-seq\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:145\u001b[0m, in \u001b[0;36mRavensDataset.load\u001b[0;34m(self, episode_id, images, cache)\u001b[0m\n\u001b[1;32m    143\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, \u001b[39m'\u001b[39m\u001b[39maction\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(path)):\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mepisode_id\u001b[39m:\u001b[39;00m\u001b[39m06d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m fname:\n\u001b[1;32m    146\u001b[0m         seed \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(fname[(fname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m])\n\u001b[1;32m    148\u001b[0m         \u001b[39m# Load data.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch_data = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, _ = batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img', 'p0', 'p0_theta', 'p1', 'p1_theta', 'perturb_params', 'lang_goal'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m train_ds:\n\u001b[1;32m      3\u001b[0m     c\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:260\u001b[0m, in \u001b[0;36mRavensDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    257\u001b[0m sample, goal \u001b[39m=\u001b[39m episode[i], episode[g]\n\u001b[1;32m    259\u001b[0m \u001b[39m# Process sample.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_sample(sample, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugment)\n\u001b[1;32m    261\u001b[0m goal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_goal(goal, perturb_params\u001b[39m=\u001b[39msample[\u001b[39m'\u001b[39m\u001b[39mperturb_params\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m sample, goal\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:172\u001b[0m, in \u001b[0;36mRavensDataset.process_sample\u001b[0;34m(self, datum, augment)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_sample\u001b[39m(\u001b[39mself\u001b[39m, datum, augment\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    170\u001b[0m     \u001b[39m# Get training labels from data sample.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     (obs, act, _, info) \u001b[39m=\u001b[39m datum\n\u001b[0;32m--> 172\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_image(obs)\n\u001b[1;32m    174\u001b[0m     p0, p1 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     p0_theta, p1_theta \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:160\u001b[0m, in \u001b[0;36mRavensDataset.get_image\u001b[0;34m(self, obs, cam_config)\u001b[0m\n\u001b[1;32m    157\u001b[0m     cam_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcam_config\n\u001b[1;32m    159\u001b[0m \u001b[39m# Get color and height maps from RGB-D images.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m cmap, hmap \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mget_fused_heightmap(\n\u001b[1;32m    161\u001b[0m     obs, cam_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbounds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpix_size)\n\u001b[1;32m    162\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((cmap,\n\u001b[1;32m    163\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m    164\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m    165\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m]), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39massert\u001b[39;00m img\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_shape, img\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/cliport/cliport/utils/utils.py:394\u001b[0m, in \u001b[0;36mget_fused_heightmap\u001b[0;34m(obs, configs, bounds, pix_size)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_fused_heightmap\u001b[39m(obs, configs, bounds, pix_size):\n\u001b[1;32m    393\u001b[0m     \u001b[39m\"\"\"Reconstruct orthographic heightmaps with segmentation masks.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     heightmaps, colormaps \u001b[39m=\u001b[39m reconstruct_heightmaps(\n\u001b[1;32m    395\u001b[0m         obs[\u001b[39m'\u001b[39;49m\u001b[39mcolor\u001b[39;49m\u001b[39m'\u001b[39;49m], obs[\u001b[39m'\u001b[39;49m\u001b[39mdepth\u001b[39;49m\u001b[39m'\u001b[39;49m], configs, bounds, pix_size)\n\u001b[1;32m    396\u001b[0m     colormaps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(colormaps)\n\u001b[1;32m    397\u001b[0m     heightmaps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(heightmaps)\n",
      "File \u001b[0;32m~/cliport/cliport/utils/utils.py:118\u001b[0m, in \u001b[0;36mreconstruct_heightmaps\u001b[0;34m(color, depth, configs, bounds, pixel_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m transform \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39m4\u001b[39m)\n\u001b[1;32m    117\u001b[0m transform[:\u001b[39m3\u001b[39m, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack((rotation, position))\n\u001b[0;32m--> 118\u001b[0m xyz \u001b[39m=\u001b[39m transform_pointcloud(xyz, transform)\n\u001b[1;32m    119\u001b[0m heightmap, colormap \u001b[39m=\u001b[39m get_heightmap(xyz, color, bounds, pixel_size)\n\u001b[1;32m    120\u001b[0m heightmaps\u001b[39m.\u001b[39mappend(heightmap)\n",
      "File \u001b[0;32m~/cliport/cliport/utils/utils.py:103\u001b[0m, in \u001b[0;36mtransform_pointcloud\u001b[0;34m(points, transform)\u001b[0m\n\u001b[1;32m    100\u001b[0m homogen_points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpad(points\u001b[39m.\u001b[39mcopy(), padding,\n\u001b[1;32m    101\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, constant_values\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m     points[\u001b[39mEllipsis\u001b[39m, i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(transform[i, :] \u001b[39m*\u001b[39;49m homogen_points, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m points\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/cliport_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/cliport_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in train_ds:\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img', 'p0', 'p0_theta', 'p1', 'p1_theta', 'perturb_params', 'lang_goal'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 160, 6)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85 67] [206 120]\n",
      "[108  35] [212  65]\n",
      "[87 44] [191  76]\n",
      "[135  68] [158  24]\n",
      "[207 156] [186  55]\n",
      "[213  44] [209  65]\n",
      "[87 70] [102  55]\n",
      "[147   5] [168   9]\n",
      "[154 130] [221  16]\n",
      "[304 135] [228  65]\n",
      "[125  21] [190 109]\n",
      "[101  98] [187  30]\n",
      "[119  13] [225  93]\n",
      "[312 118] [220  68]\n",
      "[106 106] [216  33]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m train_ds:\n\u001b[1;32m      2\u001b[0m     inp, _ \u001b[39m=\u001b[39m a\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(inp[\u001b[39m'\u001b[39m\u001b[39mp0\u001b[39m\u001b[39m'\u001b[39m], inp[\u001b[39m'\u001b[39m\u001b[39mp1\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:260\u001b[0m, in \u001b[0;36mRavensDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    257\u001b[0m sample, goal \u001b[39m=\u001b[39m episode[i], episode[g]\n\u001b[1;32m    259\u001b[0m \u001b[39m# Process sample.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_sample(sample, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugment)\n\u001b[1;32m    261\u001b[0m goal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_goal(goal, perturb_params\u001b[39m=\u001b[39msample[\u001b[39m'\u001b[39m\u001b[39mperturb_params\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m sample, goal\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:172\u001b[0m, in \u001b[0;36mRavensDataset.process_sample\u001b[0;34m(self, datum, augment)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_sample\u001b[39m(\u001b[39mself\u001b[39m, datum, augment\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    170\u001b[0m     \u001b[39m# Get training labels from data sample.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     (obs, act, _, info) \u001b[39m=\u001b[39m datum\n\u001b[0;32m--> 172\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_image(obs)\n\u001b[1;32m    174\u001b[0m     p0, p1 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     p0_theta, p1_theta \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cliport/cliport/dataset.py:160\u001b[0m, in \u001b[0;36mRavensDataset.get_image\u001b[0;34m(self, obs, cam_config)\u001b[0m\n\u001b[1;32m    157\u001b[0m     cam_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcam_config\n\u001b[1;32m    159\u001b[0m \u001b[39m# Get color and height maps from RGB-D images.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m cmap, hmap \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mget_fused_heightmap(\n\u001b[1;32m    161\u001b[0m     obs, cam_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbounds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpix_size)\n\u001b[1;32m    162\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((cmap,\n\u001b[1;32m    163\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m    164\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m    165\u001b[0m                       hmap[\u001b[39mEllipsis\u001b[39m, \u001b[39mNone\u001b[39;00m]), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39massert\u001b[39;00m img\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_shape, img\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/cliport/cliport/utils/utils.py:394\u001b[0m, in \u001b[0;36mget_fused_heightmap\u001b[0;34m(obs, configs, bounds, pix_size)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_fused_heightmap\u001b[39m(obs, configs, bounds, pix_size):\n\u001b[1;32m    393\u001b[0m     \u001b[39m\"\"\"Reconstruct orthographic heightmaps with segmentation masks.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     heightmaps, colormaps \u001b[39m=\u001b[39m reconstruct_heightmaps(\n\u001b[1;32m    395\u001b[0m         obs[\u001b[39m'\u001b[39;49m\u001b[39mcolor\u001b[39;49m\u001b[39m'\u001b[39;49m], obs[\u001b[39m'\u001b[39;49m\u001b[39mdepth\u001b[39;49m\u001b[39m'\u001b[39;49m], configs, bounds, pix_size)\n\u001b[1;32m    396\u001b[0m     colormaps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(colormaps)\n\u001b[1;32m    397\u001b[0m     heightmaps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(heightmaps)\n",
      "File \u001b[0;32m~/cliport/cliport/utils/utils.py:116\u001b[0m, in \u001b[0;36mreconstruct_heightmaps\u001b[0;34m(color, depth, configs, bounds, pixel_size)\u001b[0m\n\u001b[1;32m    114\u001b[0m rotation \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mgetMatrixFromQuaternion(config[\u001b[39m'\u001b[39m\u001b[39mrotation\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    115\u001b[0m rotation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(rotation)\u001b[39m.\u001b[39mreshape(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m transform \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m transform[:\u001b[39m3\u001b[39m, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack((rotation, position))\n\u001b[1;32m    118\u001b[0m xyz \u001b[39m=\u001b[39m transform_pointcloud(xyz, transform)\n",
      "File \u001b[0;32m~/cliport_env/lib/python3.8/site-packages/numpy/lib/twodim_base.py:216\u001b[0m, in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[1;32m    214\u001b[0m     M \u001b[39m=\u001b[39m N\n\u001b[1;32m    215\u001b[0m m \u001b[39m=\u001b[39m zeros((N, M), dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m M:\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Ensure M and k are integers, so we don't get any surprise casting\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# results in the expressions `M-k` and `M+1` used below.  This avoids\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# a problem with inputs with type (for example) np.uint64.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in train_ds:\n",
    "    inp, _ = a\n",
    "    print(inp['p0'], inp['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[1]['img'][:,:,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('cliport_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "324ebeeaac71c80d764223a438f4ca7776ceeb8ded420916023e4585707f70ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
